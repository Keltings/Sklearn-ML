{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e8058b",
   "metadata": {},
   "source": [
    "# Purpose of Machine Learning\n",
    "ML is a great tool to analyze data, find hidden patterns and rlts,and extract info to enable info-driven decisions and provide insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905414a",
   "metadata": {},
   "source": [
    "## ML Terminologies\n",
    "Observations----------Records, Samples, Examples that may contain one or more data points\n",
    "\n",
    "Features---------- Inputs or Attributes that define a given data set and are columns in a spread sheet\n",
    "\n",
    "Response--------Label, Outcome, target or some defined answers attached to the data set for the given set of data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8bf14",
   "metadata": {},
   "source": [
    "## ML Approach\n",
    "Starts with either a problem that uneed to solve or a given dataset that u need to analyze\n",
    "\n",
    "======Understand the problem/dataset\n",
    "======Extract the features from the set\n",
    "======Identify the problem type ie whether it is categorical or cont\n",
    "======Choose the right model\n",
    "======Train and test the model\n",
    "======Strive for accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe73262",
   "metadata": {},
   "source": [
    "ML can either be supervised or unsupervised. The problem type should be selected based on the type of learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f79b2",
   "metadata": {},
   "source": [
    "### Concept\n",
    "#### 1. Supervised Learning\n",
    "---the dataset used to train a model should have observations,features and responses. The model is trained to predict the 'right' response for a given set of data points\n",
    "\n",
    "---models are used to predict an outcome\n",
    "\n",
    "---the goal of this model is to 'generalize' a set so that the 'general rule' can be applied to a new data as well\n",
    "\n",
    "\n",
    "##### Data  Type\n",
    "Continous or Categorical\n",
    "###### Problem Type\n",
    "Regression or Classification\n",
    "\n",
    "####### Categories of nes based on the topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb41296",
   "metadata": {},
   "source": [
    "#### 2. Unsupervised Learning\n",
    "---ther response or the outcome of the data is not known\n",
    "\n",
    "---models re used to identify and visualize patterns in data by grouping similar types of data\n",
    "\n",
    "---the goal of the model is to 'represent' data in a way that meaningful info can be extracted\n",
    "\n",
    "#### Data  Type\n",
    "Continous or Categorical\n",
    "###### Problem Type\n",
    "Dimensionality reduction or Clustering\n",
    "\n",
    "####### Example Grouping of similar stories on differentnews network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b15f6",
   "metadata": {},
   "source": [
    "##### How it works Supervised\n",
    "\n",
    "Aknow dataset with observations, features, and response is used to create and train a ML algorithm. a predictive model, built on top of this algorithm , is the used to predict the response for a new set that has te same features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bca0",
   "metadata": {},
   "source": [
    "##### How it works Unsupervised\n",
    "a know dataset has a set of observations with features. but the response is not known the predictive model uses this features to identify how to classify and represent the data points of new or unseen data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b1c068c",
   "metadata": {},
   "source": [
    "To train Supervised learning models, data analysts usually divide  a known dataset into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ed408a",
   "metadata": {},
   "source": [
    "### Scikit Learn\n",
    "a powerfull and modern ml python lib for fully and semi automated data analysis and info extraction. it has:\n",
    "\n",
    "==== efficient tools to identify and organize problems(sup/unsup)\n",
    "==== free and open datasets\n",
    "==== rich set of libs for learning and predicting\n",
    "==== model support for every problem type\n",
    "==== model persistence\n",
    "==== open source community and vendor support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40503a47",
   "metadata": {},
   "source": [
    "###  Sklearn - Problem-Solution Approach\n",
    "it helps data scientists organize their work through its problems-soln approach by:\n",
    "== model selection & alg based on the data set type\n",
    "== estimator object reprs the model in sklean \n",
    "== model training feeding the data to model\n",
    "== predictions forcast new sets\n",
    "== model tuning thro multipleiterations\n",
    "== accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fecee",
   "metadata": {},
   "source": [
    "### Sklearn - Problem-Solution Considerations\n",
    "- Create separate objects for feature and response\n",
    "- ensure that features and response have only numericvalues\n",
    "- features and response should be inthe formof numpy nd array\n",
    "- since features and response should be inthe form arrays they should have shapes and sizes\n",
    "- features are always mapped as xand respnse as y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca42c25e",
   "metadata": {},
   "source": [
    "## Supervised Learning Models : \n",
    "### 1. Linear Regression\n",
    "- used to analyse continous data\n",
    "- most basic and widely used technique to predict a value of an attribute\n",
    "- pretty easy to use as the model doesnt require a lot of tuning\n",
    "- itrunsvery first thus time efficient"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a269fc7a",
   "metadata": {},
   "source": [
    "the linear regression eqn is based on the formula for a simple linear eqn:\n",
    "y = mx + c\n",
    "where:\n",
    "- c is the intercept\n",
    "- x is the input feature\n",
    "- m is the coeff of x\n",
    "- y is the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef253214",
   "metadata": {},
   "source": [
    "the smaller the value of SSR/SSE the more accurate the predictions which would make the model the best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900b00f",
   "metadata": {},
   "source": [
    "How does LR work?\n",
    "sklearn(class).linear_model.LR(fit_intercept(calculates he intercept for the module)=True,normalize=False(normalize the regression variable b4 performing the reg operation),copy_X=True(copies the regvar),n_jobs=1(no. of jobs tobe used for the computation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c13b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57906e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelida\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#import the boston dataset from the sklearn lib\n",
    "from sklearn.datasets import load_boston\n",
    "boston_df = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0b599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use the built in method DESCR to explore and understand the data\n",
    "print(boston_df['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38de1126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "#print the features of the set\n",
    "print(boston_df['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad34ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the data ina df\n",
    "df_boston = pd.DataFrame(boston_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8f8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set features as columns in the df\n",
    "df_boston.columns = boston_df.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8b6a031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the first five obs\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1133b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    "#print the dataset matrix(obs and feat matrix)\n",
    "print(boston_df.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3817ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "#print the shape of the target or response col\n",
    "print(boston_df.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32da50cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "#view the data within the target or respons column\n",
    "print(boston_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
